{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcd293fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "513d30f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author: Mark Vodyanitskiy (mvodya@icloud.com)\n",
      "created_at: 2025-07-13T14:26:08.378871\n",
      "filter_rules: MIN_TOTAL_POINTS=50, MIN_MOVING_POINTS=5, MIN_MAX_SPEED=20, SPEED_MOVING_MIN=10, SPEED_SANITY_MAX=800\n",
      "filtered_at: 2026-01-08T06:02:47.931391\n",
      "sources_count: 27555\n",
      "sources_size: 439.3Gb\n",
      "version: 1.0\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_filtered_20250714.h5\"\n",
    "\n",
    "if \"ds\" in vars():\n",
    "    ds.close()   # type: ignore\n",
    "\n",
    "ds = h5py.File(dataset_path, \"r\")\n",
    "for attr in ds.attrs:\n",
    "    print(f\"{attr}: {ds.attrs[attr]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed в десятых узла: 10 = 1.0 kn\n",
    "\n",
    "CHUNK_ROWS = 2_000_000\n",
    "\n",
    "MOVE_SPEED_MIN = 15        # >= 1.5 kn -> движение\n",
    "STOP_SPEED_MAX = 10         # <= 1.0 kn -> стоп\n",
    "\n",
    "STOP_CONFIRM_POINTS = 5    # сколько стоп-точек подряд нужно, чтобы считать остановился\n",
    "STOP_RADIUS_M = 150        # \"в одном месте\": радиус в метрах для подтверждения стопа\n",
    "\n",
    "GAP_SOFT_SEC = 2 * 60 * 60       # до 2 часов - не считаем разрывом трека\n",
    "GAP_HARD_SEC = 12 * 60 * 60      # >= 12 часов - считаем новым треком\n",
    "\n",
    "# Чтобы не делать огромные dt (если редкие сообщения)\n",
    "DT_CLIP_SEC = 30 * 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2328f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_day_datasets(ds: h5py.File):\n",
    "    gpos = ds[\"positions\"]\n",
    "    for yyyy in sorted(gpos.keys()):\n",
    "        for mm in sorted(gpos[yyyy].keys()):\n",
    "            for dd in sorted(gpos[yyyy][mm].keys()):\n",
    "                d = gpos[yyyy][mm][dd]\n",
    "                if isinstance(d, h5py.Dataset):\n",
    "                    yield (yyyy, mm, dd), d\n",
    "\n",
    "def ensure_group(h5: h5py.File, path: str) -> h5py.Group:\n",
    "    g = h5\n",
    "    for part in [p for p in path.split(\"/\") if p]:\n",
    "        if part not in g:\n",
    "            g = g.create_group(part)\n",
    "        else:\n",
    "            g = g[part]\n",
    "    return g\n",
    "\n",
    "def append_rows(dst_ds: h5py.Dataset, rows: np.ndarray) -> None:\n",
    "    if rows.size == 0:\n",
    "        return\n",
    "    old = dst_ds.shape[0]\n",
    "    new = old + rows.shape[0]\n",
    "    dst_ds.resize((new,))\n",
    "    dst_ds[old:new] = rows\n",
    "\n",
    "# быстрая оценка расстояния (метры) для \"в одном месте\"\n",
    "# equirectangular approximation\n",
    "def dist_m(lat1, lon1, lat2, lon2):\n",
    "    # lat/lon in degrees\n",
    "    R = 6371000.0\n",
    "    phi1 = np.deg2rad(lat1)\n",
    "    phi2 = np.deg2rad(lat2)\n",
    "    dphi = phi2 - phi1\n",
    "    dl = np.deg2rad(lon2 - lon1)\n",
    "    x = dl * np.cos((phi1 + phi2) * 0.5)\n",
    "    y = dphi\n",
    "    return R * np.sqrt(x*x + y*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d54834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_tracks_20250714_v3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/2p1h64qd4zb1g13m_f5z4z9w0000gn/T/ipykernel_6937/2070907140.py:9: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  dst.attrs[\"tracks_filled_at\"] = datetime.utcnow().isoformat()\n"
     ]
    }
   ],
   "source": [
    "out_path = \"/Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_tracks_20250714_v4.h5\"\n",
    "\n",
    "dst = h5py.File(out_path, \"w\")\n",
    "\n",
    "# copy root attrs\n",
    "for k, v in ds.attrs.items():\n",
    "    dst.attrs[k] = v\n",
    "\n",
    "dst.attrs[\"tracks_filled_at\"] = datetime.utcnow().isoformat()\n",
    "dst.attrs[\"track_rules\"] = (\n",
    "    f\"MOVE_SPEED_MIN={MOVE_SPEED_MIN}, STOP_SPEED_MAX={STOP_SPEED_MAX}, \"\n",
    "    f\"STOP_CONFIRM_POINTS={STOP_CONFIRM_POINTS}, STOP_RADIUS_M={STOP_RADIUS_M}, \"\n",
    "    f\"GAP_SOFT_SEC={GAP_SOFT_SEC}, GAP_HARD_SEC={GAP_HARD_SEC}\"\n",
    ")\n",
    "\n",
    "# copy /files, /zones, /ships as-is\n",
    "if \"files\" in ds:\n",
    "    ds.copy(\"files\", dst)\n",
    "if \"zones\" in ds:\n",
    "    ds.copy(\"zones\", dst)\n",
    "if \"ships\" in ds:\n",
    "    ds.copy(\"ships\", dst)\n",
    "\n",
    "# create /tracks (empty, append later)\n",
    "tracks_dtype = ds[\"tracks\"].dtype if \"tracks\" in ds else np.dtype([\n",
    "    (\"track_id\", \"i8\"),\n",
    "    (\"ship_id\", \"i8\"),\n",
    "    (\"start_timestamp\", \"i4\"),\n",
    "    (\"end_timestamp\", \"i4\"),\n",
    "    (\"start_lat\", \"f4\"),\n",
    "    (\"start_lon\", \"f4\"),\n",
    "    (\"end_lat\", \"f4\"),\n",
    "    (\"end_lon\", \"f4\"),\n",
    "    (\"points_count\", \"i4\"),\n",
    "])\n",
    "\n",
    "tracks_ds = dst.create_dataset(\n",
    "    \"tracks\",\n",
    "    shape=(0,), maxshape=(None,),\n",
    "    dtype=tracks_dtype,\n",
    "    chunks=True,\n",
    "    compression=\"gzip\", compression_opts=4\n",
    ")\n",
    "\n",
    "# create positions root group\n",
    "ensure_group(dst, \"positions\")\n",
    "\n",
    "print(\"Created:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a7b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ships: 372403\n",
      "State initialized.\n"
     ]
    }
   ],
   "source": [
    "ships_ids = ds[\"ships\"][\"ship_id\"].astype(np.int64, copy=False)\n",
    "N = ships_ids.size\n",
    "ship_to_idx = {int(sid): i for i, sid in enumerate(ships_ids)}\n",
    "\n",
    "print(\"Ships:\", N)\n",
    "\n",
    "# state arrays per ship\n",
    "last_ts = np.full(N, -1, dtype=np.int32)\n",
    "\n",
    "# Текущий активный track_id на судно (-1 если нет)\n",
    "cur_track_id = np.full(N, -1, dtype=np.int64)\n",
    "\n",
    "# Счетчик точек в текущем треке\n",
    "cur_points = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "# Стартовые параметры текущего трека\n",
    "trk_start_ts = np.zeros(N, dtype=np.int32)\n",
    "trk_start_lat = np.zeros(N, dtype=np.float32)\n",
    "trk_start_lon = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "# Последние известные координаты/время (для закрытия трека)\n",
    "last_lat = np.zeros(N, dtype=np.float32)\n",
    "last_lon = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "# stop confirmation state\n",
    "stop_cnt = np.zeros(N, dtype=np.int16)\n",
    "stop_ref_lat = np.zeros(N, dtype=np.float32)\n",
    "stop_ref_lon = np.zeros(N, dtype=np.float32)\n",
    "stop_active = np.zeros(N, dtype=np.bool_)   # \"мы в режиме подтверждения остановки\"\n",
    "last_destination = np.zeros(N, dtype=\"S64\")\n",
    "have_destination = np.zeros(N, dtype=np.bool_)\n",
    "\n",
    "# Глобальный track id генератор\n",
    "next_track_id = 1\n",
    "\n",
    "print(\"State initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb1fc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_track_for_ship(i: int):\n",
    "    \"\"\"\n",
    "    If ship i has an active track, append a row to /tracks and clear active state.\n",
    "    Uses last_* as end point.\n",
    "    \"\"\"\n",
    "    tid = int(cur_track_id[i])\n",
    "    if tid < 0:\n",
    "        return\n",
    "\n",
    "    row = np.zeros((1,), dtype=tracks_ds.dtype)\n",
    "    row[\"track_id\"][0] = tid\n",
    "    row[\"ship_id\"][0] = int(ships_ids[i])\n",
    "    row[\"start_timestamp\"][0] = int(trk_start_ts[i])\n",
    "    row[\"end_timestamp\"][0] = int(last_ts[i])\n",
    "    row[\"start_lat\"][0] = float(trk_start_lat[i])\n",
    "    row[\"start_lon\"][0] = float(trk_start_lon[i])\n",
    "    row[\"end_lat\"][0] = float(last_lat[i])\n",
    "    row[\"end_lon\"][0] = float(last_lon[i])\n",
    "    row[\"points_count\"][0] = int(cur_points[i])\n",
    "\n",
    "    append_rows(tracks_ds, row)\n",
    "\n",
    "    # clear track state\n",
    "    cur_track_id[i] = -1\n",
    "    cur_points[i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abc936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill track_id + write new HDF5:   0%|          | 0/826329360 [00:57<?, ?rows/s, 2024-10-29]\n",
      "Fill track_id + write new HDF5: 100%|██████████| 826329360/826329360 [1:36:44<00:00, 142362.15rows/s, 2025-07-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. tracks: 9902524 next_track_id: 9902525\n",
      "Output: /Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_tracks_20250714_v3.h5\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем общий размер для tqdm\n",
    "days = []\n",
    "total_rows = 0\n",
    "for key, day_ds in iter_day_datasets(ds):\n",
    "    days.append((key, day_ds))\n",
    "    total_rows += int(day_ds.shape[0])\n",
    "\n",
    "p = tqdm(total=total_rows, desc=\"Fill track_id + write new HDF5\", unit=\"rows\")\n",
    "\n",
    "for (yyyy, mm, dd), day_src in days:\n",
    "    p.set_postfix_str(f\"{yyyy}-{mm}-{dd}\")\n",
    "\n",
    "    # create dst day dataset (resizable)\n",
    "    g = ensure_group(dst, f\"positions/{yyyy}/{mm}\")\n",
    "    day_dst = g.create_dataset(\n",
    "        dd,\n",
    "        shape=(0,), maxshape=(None,),\n",
    "        dtype=day_src.dtype,\n",
    "        chunks=True,\n",
    "        compression=\"gzip\", compression_opts=4\n",
    "    )\n",
    "\n",
    "    n = int(day_src.shape[0])\n",
    "    for start in range(0, n, CHUNK_ROWS):\n",
    "        end = min(n, start + CHUNK_ROWS)\n",
    "        chunk = day_src[start:end]\n",
    "\n",
    "        # будем формировать output chunk как copy + track_id overwrite\n",
    "        out = chunk.copy()\n",
    "        out[\"track_id\"] = -1  # default\n",
    "\n",
    "        # sequential processing per row (one-pass state machine)\n",
    "        ship = chunk[\"ship_id\"].astype(np.int64, copy=False)\n",
    "        ts = chunk[\"timestamp\"].astype(np.int32, copy=False)\n",
    "        sp = chunk[\"speed\"].astype(np.int32, copy=False)\n",
    "        lat = chunk[\"lat\"].astype(np.float32, copy=False)\n",
    "        lon = chunk[\"lon\"].astype(np.float32, copy=False)\n",
    "        dest = chunk[\"destination\"]\n",
    "\n",
    "        for j in range(chunk.shape[0]):\n",
    "            sid = int(ship[j])\n",
    "            i = ship_to_idx.get(sid, -1)\n",
    "            if i < 0:\n",
    "                continue  # не должно быть, но на всякий\n",
    "\n",
    "            t = int(ts[j])\n",
    "            s = int(sp[j])\n",
    "            la = float(lat[j])\n",
    "            lo = float(lon[j])\n",
    "\n",
    "            # --- destination change => force end of track ---\n",
    "            cur_dest = dest[j]  # bytes (S64)\n",
    "\n",
    "            dest_changed = False\n",
    "            if have_destination[i]:\n",
    "                dest_changed = (cur_dest != last_destination[i])\n",
    "            else:\n",
    "                have_destination[i] = True\n",
    "\n",
    "            # обновим last_destination сразу (чтобы состояние соответствовало текущей точке)\n",
    "            if dest_changed:\n",
    "                last_destination[i] = cur_dest\n",
    "            else:\n",
    "                last_destination[i] = cur_dest  # можно и так, чтобы всегда актуально\n",
    "\n",
    "            # destination change НЕ должен рвать трек на ходу.\n",
    "            # Разрешаем \"force end\" только если:\n",
    "            # - сейчас точка стоповая (s <= STOP_SPEED_MAX), ИЛИ\n",
    "            # - у нас уже идет подтверждение стопа (stop_active), ИЛИ\n",
    "            # - трека и так нет (ничего закрывать), ИЛИ\n",
    "            # - позже при GAP_HARD_SEC трек закроется отдельной логикой\n",
    "            if dest_changed and cur_track_id[i] >= 0:\n",
    "                if (s <= STOP_SPEED_MAX) or stop_active[i]:\n",
    "                    close_track_for_ship(i)\n",
    "                    # сброс стоп-подтверждения, чтобы не залипало\n",
    "                    stop_cnt[i] = 0\n",
    "                    stop_active[i] = False\n",
    "                else:\n",
    "                    # движется -> игнорируем как границу трека\n",
    "                    pass\n",
    "\n",
    "            prev = int(last_ts[i])\n",
    "            if prev >= 0:\n",
    "                dt = t - prev\n",
    "                if dt <= 0:\n",
    "                    # timestamp назад/равен - игнорируем состояние, но track_id все равно ставим по текущему\n",
    "                    last_ts[i] = t\n",
    "                    last_lat[i] = la\n",
    "                    last_lon[i] = lo\n",
    "                else:\n",
    "                    if dt > DT_CLIP_SEC and dt < GAP_SOFT_SEC:\n",
    "                        dt = DT_CLIP_SEC\n",
    "\n",
    "                    # hard gap => новый трек (если был)\n",
    "                    if dt >= GAP_HARD_SEC:\n",
    "                        close_track_for_ship(i)\n",
    "                        stop_cnt[i] = 0\n",
    "                        stop_active[i] = False\n",
    "\n",
    "                    last_ts[i] = t\n",
    "                    last_lat[i] = la\n",
    "                    last_lon[i] = lo\n",
    "            else:\n",
    "                last_ts[i] = t\n",
    "                last_lat[i] = la\n",
    "                last_lon[i] = lo\n",
    "                dt = 0\n",
    "\n",
    "            is_moving = s >= MOVE_SPEED_MIN\n",
    "            is_stop_point = s <= STOP_SPEED_MAX\n",
    "\n",
    "            # --- start track on movement ---\n",
    "            if is_moving:\n",
    "                if cur_track_id[i] < 0:\n",
    "                    # start new track\n",
    "                    cur_track_id[i] = next_track_id\n",
    "                    next_track_id += 1\n",
    "\n",
    "                    trk_start_ts[i] = t\n",
    "                    trk_start_lat[i] = la\n",
    "                    trk_start_lon[i] = lo\n",
    "                    cur_points[i] = 0\n",
    "\n",
    "                # движение сбрасывает подтверждение остановки\n",
    "                stop_cnt[i] = 0\n",
    "                stop_active[i] = False\n",
    "\n",
    "            # --- stop confirmation ---\n",
    "            if is_stop_point:\n",
    "                if not stop_active[i]:\n",
    "                    stop_active[i] = True\n",
    "                    stop_cnt[i] = 1\n",
    "                    stop_ref_lat[i] = la\n",
    "                    stop_ref_lon[i] = lo\n",
    "                else:\n",
    "                    # проверим что \"в одном месте\"\n",
    "                    d = dist_m(stop_ref_lat[i], stop_ref_lon[i], la, lo)\n",
    "                    if d <= STOP_RADIUS_M:\n",
    "                        stop_cnt[i] += 1\n",
    "                    else:\n",
    "                        # \"стоп\" но сместился далеко - перезапускаем подтверждение\n",
    "                        stop_cnt[i] = 1\n",
    "                        stop_ref_lat[i] = la\n",
    "                        stop_ref_lon[i] = lo\n",
    "\n",
    "                # если набрали подтверждение остановки - конец трека\n",
    "                if stop_cnt[i] >= STOP_CONFIRM_POINTS:\n",
    "                    close_track_for_ship(i)\n",
    "                    # после закрытия оставляем stop_active, чтобы следующий трек начинался только при движении\n",
    "                    # stop_cnt можно оставить как есть\n",
    "            else:\n",
    "                # не стоп-точка\n",
    "                # если не движется, но и не стоп - ничего не делаем\n",
    "                pass\n",
    "\n",
    "            # --- assign track_id to current point ---\n",
    "            tid = int(cur_track_id[i])\n",
    "            out[\"track_id\"][j] = tid if tid >= 0 else -1\n",
    "\n",
    "            if tid >= 0:\n",
    "                cur_points[i] += 1\n",
    "\n",
    "        # write out chunk\n",
    "        append_rows(day_dst, out)\n",
    "\n",
    "        p.update(end - start)\n",
    "\n",
    "p.close()\n",
    "\n",
    "# закрываем хвостовые активные треки в конце файла\n",
    "for i in range(N):\n",
    "    if cur_track_id[i] >= 0:\n",
    "        close_track_for_ship(i)\n",
    "\n",
    "dst.flush()\n",
    "print(\"Done. tracks:\", tracks_ds.shape[0], \"next_track_id:\", next_track_id)\n",
    "print(\"Output:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d5b1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed: /Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_tracks_20250714_v3.h5\n"
     ]
    }
   ],
   "source": [
    "dst.close()\n",
    "print(\"Closed:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
