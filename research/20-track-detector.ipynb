{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd293fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/research/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513d30f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author: Mark Vodyanitskiy (mvodya@icloud.com)\n",
      "created_at: 2025-07-13T14:26:08.378871\n",
      "filter_rules: MIN_TOTAL_POINTS=50, MIN_MOVING_POINTS=5, MIN_MAX_SPEED=20, SPEED_MOVING_MIN=10, SPEED_SANITY_MAX=800\n",
      "filtered_at: 2026-01-08T06:02:47.931391\n",
      "sources_count: 27555\n",
      "sources_size: 439.3Gb\n",
      "version: 1.0\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_ship_663221_test.h5\"\n",
    "\n",
    "if \"ds\" in vars():\n",
    "    ds.close()   # type: ignore\n",
    "\n",
    "ds = h5py.File(dataset_path, \"r\")\n",
    "for attr in ds.attrs:\n",
    "    print(f\"{attr}: {ds.attrs[attr]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271b2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed в десятых узла: 10 = 1.0 kn\n",
    "\n",
    "CHUNK_ROWS = 2_000_000\n",
    "\n",
    "MOVE_SPEED_MIN = 15        # >= 1.5 kn -> движение\n",
    "STOP_SPEED_MAX = 10         # <= 1.0 kn -> стоп\n",
    "\n",
    "STOP_CONFIRM_POINTS = 5    # сколько стоп-точек подряд нужно, чтобы считать остановился\n",
    "STOP_RADIUS_M = 150        # \"в одном месте\": радиус в метрах для подтверждения стопа\n",
    "\n",
    "GAP_SOFT_SEC = 2 * 60 * 60       # до 2 часов - не считаем разрывом трека\n",
    "GAP_HARD_SEC = 12 * 60 * 60      # >= 12 часов - считаем новым треком\n",
    "GAP_DEST_SEC = 2 * 60 * 60   # если dest сменился и пропуск >= этого порога -> новый трек\n",
    "\n",
    "# Чтобы не делать огромные dt (если редкие сообщения)\n",
    "DT_CLIP_SEC = 30 * 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2328f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_day_datasets(ds: h5py.File):\n",
    "    gpos = ds[\"positions\"]\n",
    "    for yyyy in sorted(gpos.keys()):\n",
    "        for mm in sorted(gpos[yyyy].keys()):\n",
    "            for dd in sorted(gpos[yyyy][mm].keys()):\n",
    "                d = gpos[yyyy][mm][dd]\n",
    "                if isinstance(d, h5py.Dataset):\n",
    "                    yield (yyyy, mm, dd), d\n",
    "\n",
    "def ensure_group(h5: h5py.File, path: str) -> h5py.Group:\n",
    "    g = h5\n",
    "    for part in [p for p in path.split(\"/\") if p]:\n",
    "        if part not in g:\n",
    "            g = g.create_group(part)\n",
    "        else:\n",
    "            g = g[part]\n",
    "    return g\n",
    "\n",
    "def append_rows(dst_ds: h5py.Dataset, rows: np.ndarray) -> None:\n",
    "    if rows.size == 0:\n",
    "        return\n",
    "    old = dst_ds.shape[0]\n",
    "    new = old + rows.shape[0]\n",
    "    dst_ds.resize((new,))\n",
    "    dst_ds[old:new] = rows\n",
    "\n",
    "# быстрая оценка расстояния (метры) для определения, что точки в одном месте\n",
    "# equirectangular approximation\n",
    "def dist_m(lat1, lon1, lat2, lon2):\n",
    "    # lat/lon in degrees\n",
    "    R = 6371000.0\n",
    "    phi1 = np.deg2rad(lat1)\n",
    "    phi2 = np.deg2rad(lat2)\n",
    "    dphi = phi2 - phi1\n",
    "    dl = np.deg2rad(lon2 - lon1)\n",
    "    x = dl * np.cos((phi1 + phi2) * 0.5)\n",
    "    y = dphi\n",
    "    return R * np.sqrt(x*x + y*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d54834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_tracks_20250714_v4_test.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/2p1h64qd4zb1g13m_f5z4z9w0000gn/T/ipykernel_34331/3561208124.py:9: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  dst.attrs[\"tracks_filled_at\"] = datetime.utcnow().isoformat()\n"
     ]
    }
   ],
   "source": [
    "out_path = \"/Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_tracks_20250714_v4_test.h5\"\n",
    "\n",
    "dst = h5py.File(out_path, \"w\")\n",
    "\n",
    "# copy root attrs\n",
    "for k, v in ds.attrs.items():\n",
    "    dst.attrs[k] = v\n",
    "\n",
    "dst.attrs[\"tracks_filled_at\"] = datetime.utcnow().isoformat()\n",
    "dst.attrs[\"track_rules\"] = (\n",
    "    f\"MOVE_SPEED_MIN={MOVE_SPEED_MIN}, STOP_SPEED_MAX={STOP_SPEED_MAX}, \"\n",
    "    f\"STOP_CONFIRM_POINTS={STOP_CONFIRM_POINTS}, STOP_RADIUS_M={STOP_RADIUS_M}, \"\n",
    "    f\"GAP_SOFT_SEC={GAP_SOFT_SEC}, GAP_HARD_SEC={GAP_HARD_SEC}\"\n",
    ")\n",
    "\n",
    "# copy /files, /zones, /ships as-is\n",
    "if \"files\" in ds:\n",
    "    ds.copy(\"files\", dst)\n",
    "if \"zones\" in ds:\n",
    "    ds.copy(\"zones\", dst)\n",
    "if \"ships\" in ds:\n",
    "    ds.copy(\"ships\", dst)\n",
    "\n",
    "# create /tracks (empty, append later)\n",
    "tracks_dtype = ds[\"tracks\"].dtype if \"tracks\" in ds else np.dtype([\n",
    "    (\"track_id\", \"i8\"),\n",
    "    (\"ship_id\", \"i8\"),\n",
    "    (\"start_timestamp\", \"i4\"),\n",
    "    (\"end_timestamp\", \"i4\"),\n",
    "    (\"start_lat\", \"f4\"),\n",
    "    (\"start_lon\", \"f4\"),\n",
    "    (\"end_lat\", \"f4\"),\n",
    "    (\"end_lon\", \"f4\"),\n",
    "    (\"points_count\", \"i4\"),\n",
    "])\n",
    "\n",
    "tracks_ds = dst.create_dataset(\n",
    "    \"tracks\",\n",
    "    shape=(0,), maxshape=(None,),\n",
    "    dtype=tracks_dtype,\n",
    "    chunks=True,\n",
    "    compression=\"gzip\", compression_opts=4\n",
    ")\n",
    "\n",
    "# create positions root group\n",
    "ensure_group(dst, \"positions\")\n",
    "\n",
    "print(\"Created:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715a7b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ships: 372403\n",
      "State initialized.\n"
     ]
    }
   ],
   "source": [
    "ships_ids = ds[\"ships\"][\"ship_id\"].astype(np.int64, copy=False)\n",
    "N = ships_ids.size\n",
    "ship_to_idx = {int(sid): i for i, sid in enumerate(ships_ids)}\n",
    "\n",
    "print(\"Ships:\", N)\n",
    "\n",
    "# state arrays per ship\n",
    "last_ts = np.full(N, -1, dtype=np.int32)\n",
    "\n",
    "# Текущий активный track_id на судно (-1 если нет)\n",
    "cur_track_id = np.full(N, -1, dtype=np.int64)\n",
    "\n",
    "# Счетчик точек в текущем треке\n",
    "cur_points = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "# Стартовые параметры текущего трека\n",
    "trk_start_ts = np.zeros(N, dtype=np.int32)\n",
    "trk_start_lat = np.zeros(N, dtype=np.float32)\n",
    "trk_start_lon = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "# Последние известные координаты/время (для закрытия трека)\n",
    "last_lat = np.zeros(N, dtype=np.float32)\n",
    "last_lon = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "# stop confirmation state\n",
    "stop_cnt = np.zeros(N, dtype=np.int16)\n",
    "stop_ref_lat = np.zeros(N, dtype=np.float32)\n",
    "stop_ref_lon = np.zeros(N, dtype=np.float32)\n",
    "stop_active = np.zeros(N, dtype=np.bool_)   # \"мы в режиме подтверждения остановки\"\n",
    "last_destination = np.zeros(N, dtype=\"S64\")\n",
    "have_destination = np.zeros(N, dtype=np.bool_)\n",
    "\n",
    "# Глобальный track id генератор\n",
    "next_track_id = 1\n",
    "\n",
    "print(\"State initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1fc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_track_for_ship(i: int):\n",
    "    \"\"\"\n",
    "    If ship i has an active track, append a row to /tracks and clear active state.\n",
    "    Uses last_* as end point.\n",
    "    \"\"\"\n",
    "    tid = int(cur_track_id[i])\n",
    "    if tid < 0:\n",
    "        return\n",
    "\n",
    "    row = np.zeros((1,), dtype=tracks_ds.dtype)\n",
    "    row[\"track_id\"][0] = tid\n",
    "    row[\"ship_id\"][0] = int(ships_ids[i])\n",
    "    row[\"start_timestamp\"][0] = int(trk_start_ts[i])\n",
    "    row[\"end_timestamp\"][0] = int(last_ts[i])\n",
    "    row[\"start_lat\"][0] = float(trk_start_lat[i])\n",
    "    row[\"start_lon\"][0] = float(trk_start_lon[i])\n",
    "    row[\"end_lat\"][0] = float(last_lat[i])\n",
    "    row[\"end_lon\"][0] = float(last_lon[i])\n",
    "    row[\"points_count\"][0] = int(cur_points[i])\n",
    "\n",
    "    append_rows(tracks_ds, row)\n",
    "\n",
    "    # clear track state\n",
    "    cur_track_id[i] = -1\n",
    "    cur_points[i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abc936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill track_id + write new HDF5: 100%|██████████| 21182/21182 [00:00<00:00, 45473.10rows/s, 2025-07-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. tracks: 113 next_track_id: 114\n",
      "Output: /Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_tracks_20250714_v4_test.h5\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем общий размер для tqdm\n",
    "days = []\n",
    "total_rows = 0\n",
    "for key, day_ds in iter_day_datasets(ds):\n",
    "    days.append((key, day_ds))\n",
    "    total_rows += int(day_ds.shape[0])\n",
    "\n",
    "p = tqdm(total=total_rows, desc=\"Fill track_id + write new HDF5\", unit=\"rows\")\n",
    "\n",
    "for (yyyy, mm, dd), day_src in days:\n",
    "    p.set_postfix_str(f\"{yyyy}-{mm}-{dd}\")\n",
    "\n",
    "    # create dst day dataset (resizable)\n",
    "    g = ensure_group(dst, f\"positions/{yyyy}/{mm}\")\n",
    "    day_dst = g.create_dataset(\n",
    "        dd,\n",
    "        shape=(0,), maxshape=(None,),\n",
    "        dtype=day_src.dtype,\n",
    "        chunks=True,\n",
    "        compression=\"gzip\", compression_opts=4\n",
    "    )\n",
    "\n",
    "    n = int(day_src.shape[0])\n",
    "    for start in range(0, n, CHUNK_ROWS):\n",
    "        end = min(n, start + CHUNK_ROWS)\n",
    "        chunk = day_src[start:end]\n",
    "\n",
    "        # output chunk = copy + overwrite track_id\n",
    "        out = chunk.copy()\n",
    "        out[\"track_id\"] = -1  # default\n",
    "\n",
    "        # chunk fields\n",
    "        ship = chunk[\"ship_id\"].astype(np.int64, copy=False)\n",
    "        ts   = chunk[\"timestamp\"].astype(np.int32, copy=False)\n",
    "        sp   = chunk[\"speed\"].astype(np.int32, copy=False)\n",
    "        lat  = chunk[\"lat\"].astype(np.float32, copy=False)\n",
    "        lon  = chunk[\"lon\"].astype(np.float32, copy=False)\n",
    "        dest = chunk[\"destination\"]  # bytes S64\n",
    "\n",
    "        for j in range(chunk.shape[0]):\n",
    "            sid = int(ship[j])\n",
    "            i = ship_to_idx.get(sid, -1)\n",
    "            if i < 0:\n",
    "                continue\n",
    "\n",
    "            t  = int(ts[j])\n",
    "            s  = int(sp[j])\n",
    "            la = float(lat[j])\n",
    "            lo = float(lon[j])\n",
    "            cur_dest = dest[j]  # bytes\n",
    "\n",
    "            # 1) dt / gaps / update last\n",
    "            prev = int(last_ts[i])\n",
    "            if prev >= 0:\n",
    "                dt = t - prev\n",
    "                if dt <= 0:\n",
    "                    # time went backwards or equal => just update last and continue logic\n",
    "                    dt = 0\n",
    "                else:\n",
    "                    # clip moderate dt (optional) but keep real \"big gap\" detection\n",
    "                    if dt > DT_CLIP_SEC and dt < GAP_SOFT_SEC:\n",
    "                        dt = DT_CLIP_SEC\n",
    "\n",
    "                    # HARD GAP => end current track unconditionally (if any)\n",
    "                    if dt >= GAP_HARD_SEC:\n",
    "                        close_track_for_ship(i)\n",
    "                        stop_cnt[i] = 0\n",
    "                        stop_active[i] = False\n",
    "\n",
    "                # update last point\n",
    "                last_ts[i]  = t\n",
    "                last_lat[i] = la\n",
    "                last_lon[i] = lo\n",
    "            else:\n",
    "                # first seen point\n",
    "                dt = 0\n",
    "                last_ts[i]  = t\n",
    "                last_lat[i] = la\n",
    "                last_lon[i] = lo\n",
    "\n",
    "            # 2) classify point\n",
    "            is_moving     = (s >= MOVE_SPEED_MIN)\n",
    "            is_stop_point = (s <= STOP_SPEED_MAX)\n",
    "\n",
    "            # 3) destination change logic (AFTER dt is known)\n",
    "            #    rule: don't cut on-the-fly, only:\n",
    "            #      a) stop-ish (stop point or stop_active) OR\n",
    "            #      b) dest_changed + dt >= GAP_DEST_SEC\n",
    "            dest_changed = False\n",
    "            if have_destination[i]:\n",
    "                dest_changed = (cur_dest != last_destination[i])\n",
    "            else:\n",
    "                have_destination[i] = True\n",
    "\n",
    "            # always keep last_destination current\n",
    "            last_destination[i] = cur_dest\n",
    "\n",
    "            if dest_changed and (cur_track_id[i] >= 0):\n",
    "                if is_stop_point or stop_active[i]:\n",
    "                    close_track_for_ship(i)\n",
    "                    stop_cnt[i] = 0\n",
    "                    stop_active[i] = False\n",
    "                elif dt >= GAP_DEST_SEC:\n",
    "                    close_track_for_ship(i)\n",
    "                    stop_cnt[i] = 0\n",
    "                    stop_active[i] = False\n",
    "                else:\n",
    "                    # moving without meaningful gap -> ignore\n",
    "                    pass\n",
    "\n",
    "            # 4) stop confirmation (can end track)\n",
    "            #    NOTE: if we are moving -> reset stop state\n",
    "            if is_moving:\n",
    "                stop_cnt[i] = 0\n",
    "                stop_active[i] = False\n",
    "            elif is_stop_point:\n",
    "                if not stop_active[i]:\n",
    "                    stop_active[i] = True\n",
    "                    stop_cnt[i] = 1\n",
    "                    stop_ref_lat[i] = la\n",
    "                    stop_ref_lon[i] = lo\n",
    "                else:\n",
    "                    d = dist_m(stop_ref_lat[i], stop_ref_lon[i], la, lo)\n",
    "                    if d <= STOP_RADIUS_M:\n",
    "                        stop_cnt[i] += 1\n",
    "                    else:\n",
    "                        stop_cnt[i] = 1\n",
    "                        stop_ref_lat[i] = la\n",
    "                        stop_ref_lon[i] = lo\n",
    "\n",
    "                if stop_cnt[i] >= STOP_CONFIRM_POINTS:\n",
    "                    close_track_for_ship(i)\n",
    "                    # keep stop_active True (optional) — так трек стартанёт только при движении\n",
    "                    # stop_cnt можно оставить\n",
    "\n",
    "            # 5) start track on movement (ONLY here)\n",
    "            if is_moving and (cur_track_id[i] < 0):\n",
    "                cur_track_id[i] = next_track_id\n",
    "                next_track_id += 1\n",
    "\n",
    "                trk_start_ts[i]  = t\n",
    "                trk_start_lat[i] = la\n",
    "                trk_start_lon[i] = lo\n",
    "                cur_points[i] = 0\n",
    "\n",
    "            # 6) assign track_id to current point\n",
    "            tid = int(cur_track_id[i])\n",
    "            out[\"track_id\"][j] = tid if tid >= 0 else -1\n",
    "            if tid >= 0:\n",
    "                cur_points[i] += 1\n",
    "\n",
    "        # write out chunk\n",
    "        append_rows(day_dst, out)\n",
    "        p.update(end - start)\n",
    "\n",
    "p.close()\n",
    "\n",
    "# close tail tracks\n",
    "for i in range(N):\n",
    "    if cur_track_id[i] >= 0:\n",
    "        close_track_for_ship(i)\n",
    "\n",
    "dst.flush()\n",
    "print(\"Done. tracks:\", tracks_ds.shape[0], \"next_track_id:\", next_track_id)\n",
    "print(\"Output:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d5b1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed: /Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_tracks_20250714_v4_test.h5\n"
     ]
    }
   ],
   "source": [
    "dst.close()\n",
    "print(\"Closed:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
