{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e939424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c713796",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = \"/Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_filtered_20250714.h5\"\n",
    "DST_PATH = \"/Volumes/SSD/mark/Documents/Works/MT_Dataset/mt_ship_663221_test.h5\"\n",
    "\n",
    "TARGET_SHIP_ID = 20744\n",
    "CHUNK_ROWS = 500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1df856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_group(h5: h5py.File | h5py.Group, path: str) -> h5py.Group:\n",
    "    if path in h5:\n",
    "        return h5[path]\n",
    "    return h5.create_group(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98094c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter positions by ship_id: 100%|██████████| 826329360/826329360 [04:23<00:00, 3141512.33rows/s]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(SRC_PATH, \"r\") as src, h5py.File(DST_PATH, \"w\") as dst:\n",
    "    # Копируем attrs файла\n",
    "    for k, v in src.attrs.items():\n",
    "        dst.attrs[k] = v\n",
    "\n",
    "    # Копируем все кроме positions\n",
    "    for key in src.keys():\n",
    "        if key == \"positions\":\n",
    "            continue\n",
    "        src.copy(key, dst)\n",
    "\n",
    "    # Обрабатываем positions\n",
    "    src_pos = src[\"positions\"]\n",
    "    dst_pos = dst.create_group(\"positions\")\n",
    "\n",
    "    # Посчитаем общее число строк для tqdm\n",
    "    total_rows = 0\n",
    "    days = []\n",
    "\n",
    "    for yyyy in src_pos:\n",
    "        for mm in src_pos[yyyy]:\n",
    "            for dd in src_pos[yyyy][mm]:\n",
    "                ds_day = src_pos[yyyy][mm][dd]\n",
    "                days.append((yyyy, mm, dd, ds_day))\n",
    "                total_rows += ds_day.shape[0]\n",
    "\n",
    "    pbar = tqdm(total=total_rows, desc=\"Filter positions by ship_id\", unit=\"rows\")\n",
    "\n",
    "    for yyyy, mm, dd, day_src in days:\n",
    "        out_chunks = []\n",
    "\n",
    "        n = day_src.shape[0]\n",
    "        for start in range(0, n, CHUNK_ROWS):\n",
    "            end = min(n, start + CHUNK_ROWS)\n",
    "            chunk = day_src[start:end]\n",
    "\n",
    "            mask = chunk[\"ship_id\"] == TARGET_SHIP_ID\n",
    "            if np.any(mask):\n",
    "                out_chunks.append(chunk[mask])\n",
    "\n",
    "            pbar.update(end - start)\n",
    "\n",
    "        if not out_chunks:\n",
    "            continue  # в этот день нужного судна нет\n",
    "\n",
    "        out = np.concatenate(out_chunks)\n",
    "\n",
    "        g_year = ensure_group(dst_pos, yyyy)\n",
    "        g_month = ensure_group(g_year, mm)\n",
    "\n",
    "        g_month.create_dataset(\n",
    "            dd,\n",
    "            data=out,\n",
    "            maxshape=(None,),\n",
    "            chunks=True,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=4,\n",
    "        )\n",
    "\n",
    "    pbar.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
